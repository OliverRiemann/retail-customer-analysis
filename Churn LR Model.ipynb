{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dec0eba7-2c51-4907-97f3-1dff476c6a46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Churn prediction Model\n",
    "\n",
    "This notebook defines a function which takes in a RFM dataframe and trains (and evaluates) a Logistic regression model to predict churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "094a9a3b-198f-48cc-9cc7-200f1df5ee14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import os\n",
    "os.environ[\"MLFLOW_DFS_TMP\"] = \"/Volumes/portfolio/cltv_schema/portfolio_crm/mlflow_tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abf59c65-661b-4d5c-ab99-fc5ad1589fba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rfm_data = spark.read.format(\"delta\").load(\"/Volumes/portfolio/cltv_schema/portfolio_crm/rfm_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "995571cf-e7b5-4674-902d-5f709e01f0c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def lr_model(\n",
    "    rfm_data: DataFrame, \n",
    "    churn_recency: int = 90, \n",
    "    model_path: str = \"/Volumes/portfolio/cltv_schema/portfolio_crm/churn_model\"\n",
    "):\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"churn_recency\", churn_recency)\n",
    "\n",
    "        # Create churn label\n",
    "        rfm = rfm_data.withColumn(\"Churn\", (rfm_data[\"Recency\"] > churn_recency).cast(\"integer\"))\n",
    "\n",
    "        features = [\"Recency\", \"Frequency\", \"Monetary\"]\n",
    "        assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "        lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Churn\")\n",
    "\n",
    "        pipeline = Pipeline(stages=[assembler, lr])\n",
    "        train, test = rfm.randomSplit([0.8, 0.2])\n",
    "        model = pipeline.fit(train)\n",
    "\n",
    "        # Save the model to Unity Catalog volume\n",
    "        model.write().overwrite().save(model_path)\n",
    "\n",
    "        # Evaluate\n",
    "        preds = model.transform(test)\n",
    "        roc_auc = BinaryClassificationEvaluator(labelCol=\"Churn\", metricName=\"areaUnderROC\").evaluate(preds)\n",
    "        pr_auc = BinaryClassificationEvaluator(labelCol=\"Churn\", metricName=\"areaUnderPR\").evaluate(preds)\n",
    "        accuracy = MulticlassClassificationEvaluator(labelCol=\"Churn\", metricName=\"accuracy\").evaluate(preds)\n",
    "\n",
    "        print(f\"ROC AUC: {roc_auc}, PR AUC: {pr_auc}, Accuracy: {accuracy}\")\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"pr_auc\", pr_auc)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        os.environ[\"MLFLOW_DFS_TMP\"] = \"/Volumes/portfolio/cltv_schema/portfolio_crm/mlflow_tmp\"\n",
    "\n",
    "        # Log model to MLflow (in addition to saving to the volume)\n",
    "        mlflow.spark.log_model(model, \"churn_lr_model\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "111d41c0-9377-435d-82da-587a25dc006a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_model(rfm_data)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Churn LR Model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
